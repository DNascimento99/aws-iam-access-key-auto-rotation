AWSTemplateFormatVersion: 2010-09-09

Metadata:

  AWS::CloudFormation::Interface:
    ParameterGroups:
    
      #Import CSV to DynamoDB
      - Label:
          default: Tool to Automate Importing CSV files into DynamoDB (Account ID to Account Email Data Mapping Table)
        Parameters:
          - pImportCSVBucketName
          - pCSVFileName
          - pDynamoDBTableName
          
      #Emailer Tool
      - Label:
          default: Tool to Automate Emailing End Users Based on Config Violations
        Parameters:
          - pEmailerToolFunctionZipFile
          - pS3BucketEmailTemplates
          - pAdminEmailSource

          
    ParameterLabels:
    
      #Import CSV to DynamoDB
      pImportCSVBucketName:
        default: S3 Bucket Name
      pCSVFileName:
        default: CSV File Name
      pDynamoDBTableName:
        default: DynamoDB Table Name (all lowercase)
        
      #Emailer Tool
      pEmailerToolFunctionZipFile:
        default: Lambda Zip File
      pAdminEmailSource:
        default: Admin Email Address to Use for Email Source Attribute
      pS3BucketEmailTemplates:
        default: S3 Bucket for Email Templates


Parameters:

#dup value
  pLambdaFunctionS3BucketName:
    Type: String
    Default: ''
    Description: Name of the S3 Bucket that houses your Lambda function code.

#Import CSV to DynamoDB
  pImportCSVBucketName:
    Description: Name of the S3 bucket you will deploy the CSV file to
    Type: String
    ConstraintDescription: must be a valid bucket name.
  pCSVFileName:
    Description: Name of the S3 file (including suffix)
    Type: String
    Default: ''
    ConstraintDescription: Valid S3 file name.
  pDynamoDBTableName:
    Description: Name of the dynamoDB table you will use
    Type: String
    Default: 'aws-account-emails'
    ConstraintDescription: must be a valid dynamoDB name.
    
#Emailer Tool
  pEmailerToolFunctionZipFile:
    Type: String
    Default: EmailerTool.zip
    Description: The zip file for your emailer tool Lambda Function.
  pAdminEmailSource:
    Description: Email address that will be used in the 'sent from' section of the email.
    Type: String
  pS3BucketEmailTemplates:
    Description: Name of the S3 file (including suffix) for Email Templates
    Type: String
    Default: ''
    ConstraintDescription: Valid S3 file name.
    
    
Resources:

#Import CSV to DynamoDB
  rDynamoDBTable:
    Type: 'AWS::DynamoDB::Table'
    Properties:
      TableName: !Ref pDynamoDBTableName
      BillingMode: PAY_PER_REQUEST
      AttributeDefinitions:
        - AttributeName: uuid
          AttributeType: S
      KeySchema:
        - AttributeName: uuid
          KeyType: HASH
      Tags:
        - Key: Name
          Value: !Ref pDynamoDBTableName
  CsvToDDBLambdaRole:
    Type: 'AWS::IAM::Role'
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
                - s3.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      Path: /
      ManagedPolicyArns:
        - 'arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole'
        - 'arn:aws:iam::aws:policy/AWSLambdaInvocation-DynamoDB'
        - 'arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess'
      Policies:
        - PolicyName: policyname
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Resource: '*'
                Action:
                  - 'dynamodb:PutItem'
                  - 'dynamodb:BatchWriteItem'
  CsvToDDBLambdaFunction:
    Type: 'AWS::Lambda::Function'
    Properties:
      Handler: index.lambda_handler
      Description: Automated importing a csv file from S3 into a DynamoDB table (specifically formated to work with 'accountid,accountname,accountemail,accountowner')
      FunctionName: CSV-to-DynamoDB-Import-Tool
      Role: !GetAtt 
        - CsvToDDBLambdaRole
        - Arn
      Code:
        ZipFile: !Join 
          - |+

          - - import json
            - import boto3
            - import os
            - import csv
            - import codecs
            - import sys
            - ''
            - s3 = boto3.resource('s3')
            - dynamodb = boto3.resource('dynamodb')
            - ''
            - 'bucket = os.environ[''bucket'']'
            - 'key = os.environ[''key'']'
            - 'tableName = os.environ[''table'']'
            - ''
            - 'def lambda_handler(event, context):'
            - ''
            - ''
            - '   #get() does not store in memory'
            - '   try:'
            - '       obj = s3.Object(bucket, key).get()[''Body'']'
            - '   except:'
            - '       print("S3 Object could not be opened. Check environment variable. ")'
            - '   try:'
            - '       table = dynamodb.Table(tableName)'
            - '   except:'
            - '       print("Error loading DynamoDB table. Check if table was created correctly and environment variable.")'
            - ''
            - '   #DictReader is a generator; not stored in memory'
            - '   for row in csv.DictReader(codecs.getreader(''utf-8-sig'')(obj)):'
            - '      accountid = row[''accountid'']'
            - '      accountname = row[''accountname'']'
            - '      accountemail = row[''accountemail'']'
            - '      accountowner = row[''accountowner'']'
            - ''
            - '      write_to_dynamo(accountid,accountname,accountemail,accountowner)'
            - ''
            - '   return {'
            - '      ''statusCode'': 200,'
            - '      ''body'': json.dumps(''Uploaded to DynamoDB Table'')'
            - '   }'
            - ''
            - ''
            - 'def write_to_dynamo(accountid,accountname,email,owner):'
            - '   dynamodb_client = boto3.client(''dynamodb'')'
            - ''
            - '   try:'
            - '      table = dynamodb.Table(tableName)'
            - '   except:'
            - '      print("Error loading DynamoDB table. Check if table was created correctly and environment variable.")'
            - ''
            - '   response = dynamodb_client.put_item('
            - '      TableName=tableName,'
            - '      Item={'
            - '         ''uuid'': {'
            - '            ''S'': accountid'
            - '         },'
            - '         ''accountid'': {'
            - '            ''S'': accountid'
            - '         },'
            - '         ''accountname'': {'
            - '            ''S'': accountname'
            - '         },'
            - '         ''accountemail'': {'
            - '            ''S'': email'
            - '         },'
            - '         ''accountowner'': {'
            - '            ''S'': owner'
            - '         }'
            - '      }'
            - '   )'
      Runtime: python3.7
      Timeout: 900
      MemorySize: 3008
      Environment:
        Variables:
          bucket: !Ref pImportCSVBucketName
          key: !Ref pCSVFileName
          table: !Ref pDynamoDBTableName
  
  rCSVS3Bucket:
    DependsOn:
      - CsvToDDBLambdaFunction
      - rCSVBucketPermission
    Type: 'AWS::S3::Bucket'
    Properties:
      BucketName: !Ref pImportCSVBucketName
      AccessControl: BucketOwnerFullControl
      NotificationConfiguration:
        LambdaConfigurations:
          - Event: 's3:ObjectCreated:*'
            Function: !GetAtt 
              - CsvToDDBLambdaFunction
              - Arn
  rCSVBucketPermission:
    Type: 'AWS::Lambda::Permission'
    Properties:
      Action: 'lambda:InvokeFunction'
      FunctionName: !Ref CsvToDDBLambdaFunction
      Principal: s3.amazonaws.com
      SourceAccount: !Ref 'AWS::AccountId'


#Emailer Tool
  rEmailerToolBucket:
    DependsOn:
      - rEmailerToolLambdaFunction
      - rEmailerToolBucketPermission
    Type: 'AWS::S3::Bucket'
    Properties:
      BucketName: !Ref pS3BucketEmailTemplates
      AccessControl: BucketOwnerFullControl
      NotificationConfiguration:
        LambdaConfigurations:
          - Event: 's3:ObjectCreated:*'
            Function: !GetAtt 
              - CsvToDDBLambdaFunction
              - Arn
  rEmailerToolBucketPermission:
    Type: 'AWS::Lambda::Permission'
    Properties:
      Action: 'lambda:InvokeFunction'
      FunctionName: !Ref CsvToDDBLambdaFunction
      Principal: s3.amazonaws.com
      SourceAccount: !Ref 'AWS::AccountId'

  rEmailerToolFunctionExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Sid: AllowExecutionPermissionsOnFunction
            Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Path: /
      Policies:
        - PolicyName: AllowS3ZipRetrieval
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:GetObject
                Resource:
                  - !Sub 'arn:aws:s3:::${pS3BucketEmailTemplates}/*'
              - Effect: Allow
                Action:
                  - dynamodb:GetItem
                Resource: !GetAtt rDynamoDBTable.Arn
              - Effect: Allow
                Action:
                  - ses:SendEmail
                Resource: "*"

  rEmailerToolLambdaFunction:
    Type: AWS::Lambda::Function
    Properties:
      Description: Function that received SNS events from config rules and emails end users who own the account id of the resource violation.
      FunctionName: Direct-to-End-User-Emailing-Tool
      Handler: index.lambda_handler
      Runtime: python3.8
      Role: !GetAtt 'rEmailerToolFunctionExecutionRole.Arn'
      Timeout: 300
      Environment:
        Variables:
          admin_email_source: !Ref pAdminEmailSource
          dynamodb_table_name: !Ref pDynamoDBTableName
          s3_bucket_name: !Ref pS3BucketEmailTemplates
      Code:
        S3Bucket: !Ref pLambdaFunctionS3BucketName
        S3Key: !Ref pEmailerToolFunctionZipFile

